{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ffa6e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0c4df36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c646a590",
   "metadata": {},
   "source": [
    "# Intro to Autogen and RAG\n",
    "Notebook focuses on creating..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90465a",
   "metadata": {},
   "source": [
    "## Import ChromaDB and configure local store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36a07d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Create file-based vector store\n",
    "# NOTE: turned off telemetry as causing error\n",
    "client_settings = Settings(\n",
    "    anonymized_telemetry=False,\n",
    ")\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\", settings=client_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3658af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# Create (or load) a collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"rag_collection\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bebf1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: 0\n",
      "Add of existing embedding ID: 0\n",
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "Insert of existing embedding ID: 1\n",
      "Add of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Add of existing embedding ID: 2\n"
     ]
    }
   ],
   "source": [
    "# Add some sample docs (can replace later with PDFs, scraped text, embeddings)\n",
    "docs = [\n",
    "    \"AutoGen is a framework for building multi-agent systmes.\",\n",
    "    \"RAG stands for Retrieval-Augmented Generation.\",\n",
    "    \"Vector databases store embeddings for semantic search.\"\n",
    "]\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    collection.add(\n",
    "        documents=[doc],\n",
    "        ids=[str(i)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3404b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple retriever helper\n",
    "def retrieve(query, k=3):\n",
    "    results = collection.query(query_texts=[query], n_results=k)\n",
    "    return results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd71ca7",
   "metadata": {},
   "source": [
    "## Create AutoGen Agents\n",
    "### Load API Key and Configure LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6def9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "# Load environment varaibles\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3141882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM configuration\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "else:\n",
    "    print(\"Unable to load OPENAI_API_KEY\")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model = 'gpt-4o', api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f98b2d",
   "metadata": {},
   "source": [
    "### Create Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b79ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AssistantAGent\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client\n",
    ")\n",
    "\n",
    "# Create UserProxyAgent\n",
    "user = UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    input_func=\"NEVER\"    # agent will run without needing to pause for human input\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294f651",
   "metadata": {},
   "source": [
    "## Create RAG wrapper for AutoGen assistant\n",
    "Combines\n",
    "- user's query\n",
    "- retrieved context\n",
    "- structured prompt\n",
    "- AutoGen assistant agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a89b4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rag_answer(query:str):\n",
    "    # Retrieve context\n",
    "    context_docs = retrieve(query)\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "\n",
    "    # Build agumented prompt\n",
    "    prompt = f\"\"\"\n",
    "    Use the following context to answer the question.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    # Send to Autogen Assistant\n",
    "    result = await assistant.run(task=prompt)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee64c7",
   "metadata": {},
   "source": [
    "## Test RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0d775bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briannabesinaiz/Documents/04_Projects/GITHUB/repos/python_portfolio/python-portfolio/autogen_lab/autogen_venv/lib/python3.11/site-packages/pydantic/_internal/_typing_extra.py:492: RuntimeWarning: coroutine 'BaseChatAgent.run' was never awaited\n",
      "  return _eval_type(value, globalns, localns, type_params)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGen is a framework for building multi-agent systems. TERMINATE\n"
     ]
    }
   ],
   "source": [
    "result = await rag_answer(\"What is AutoGen?\")\n",
    "print(result.messages[-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
